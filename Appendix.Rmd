---
title: "Appendix"
author: "Yunran Chen"
date: "2017/12/11"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r library, message=FALSE, warning=FALSE, paged.print=FALSE}
library(tibble)
library(dplyr)
library(purrr)
library(tidyr)
library(ggplot2)
library(stringr)
library(BAS)
library("R2jags")
library(knitr)

bioassay.read = read.table("http://stat.duke.edu/sites/stat.duke.edu/files/bioassay.txt",
                       header=T,stringsAsFactors = FALSE) %>% as.tibble()

bioassay=bind_cols(map_df(bioassay.read %>% select(uterus,weight,EE,ZM),~.x %>% as.numeric(.)),
                   map_df(bioassay.read %>% select(protocol,lab,group),~.x %>% as.factor(.))
                   ) %>% as.tibble()
bioassay.fac=bioassay %>% mutate(EE=as.factor(EE),ZM=as.factor(ZM))
X.fac=model.matrix(data=bioassay.fac,object =~ EE+ZM+lab+protocol+weight+EE:protocol+ZM:protocol+EE:lab+ZM:lab)
```

Containing Part I to Part IV

I use three different ways to settle down the problems. For part I(MLE), I mainly use t-test and F-test. For part II(BMA with hyper-g-n prior), I mainly use the posterior model probability, inclusive probability and the posterior pdf for each predictor. For part III(jags), I would just use visualization (Credible Interval) to illustrate. Actually, for each part, we can use boxplot to illustrate for convenience and directly. The long table and graph would be attached at the end of the document.

### Part IV

The three method can get the same result for 

Uterotrophic bioassay successful overall at identifying effects. Some labs fail to detect such effects. The dose response vary across labs. All three methods agree that "Huntingd","Poulenc" stands out as being different from each other. The protocols differ in their sensitivity to detect the effects. Protocol B is recommeded.

The main difference:

1.The frequentists act more strict. For "outliers", they show less tolerence. For the changing dose point, they require more.(EE3 v.s. EE1) Generally, Baysian methods take uncertainty into consideration which behave more "moderate".

Method 3 (jags) showing more tolerence for "outliers" than Method 2 (bma) than Method 1 (MLE). This is because I adopted a prior with heavy tail in Method 3. Some "outliers" considered by Method1 may be "normal" in method 2,3("Bayer"). Some "outlier" considered by method 2 may be "normal" in method 1,3.("TNO")

2.It is easy for frequentist to get the estimation of parameters. But it is complex to construct suitable test. Although it is really time-consuming to get the posterior distribution of parameters. But it would be easier to analysis based on the data. And the solution seems more natural.

Improvements:

1.I use different methods to answer the questions in three parts. So it may be hard to compare.

2. For PartIII, I should adopt a prior for selecting the variable to decrease the computation.

 
### Part I

#### summary

```{r summary,  message=FALSE, warning=FALSE, paged.print=FALSE}
##1)We can consider `weight` and `uterus` as continuous variable. All other variables only have seperate values.
summary(bioassay)
bioassay %>% select(EE) %>% table()
bioassay %>% select(ZM) %>% table()
##2)There are significant interaction among variables. Because each labs adopted differet treatment.
table(bioassay$EE,bioassay.fac$lab)
##visualization for points
#ggplot(data=bioassay,mapping = aes(y = lab,x = protocol,color=as.factor(ZM)))+
#  geom_jitter(alpha=0.5)
#ggplot(data=bioassay.fac,mapping = aes(y = lab,x = ZM,color=protocol))+
#  geom_jitter(alpha=0.5)
#ggplot(data=bioassay,mapping = aes(y = lab,x = protocol,color=as.factor(EE)))+
#  geom_jitter(alpha=0.5)
#ggplot(data=bioassay,mapping = aes(y = lab,x = protocol,color=as.factor(EE)))+
#     geom_count(alpha=0.5,position = "jitter")
```

#### EDA

```{r EDA, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
##---------------------boxplot
##different labs have diff mean on ZM. interaction on labs and protocol.
##when consider ZM as numeric, the diff is not sig in pic. but in factor - diff.
###4var:ZM

outliers=c(1426,926,1586)#,1425,1946,2666)
ggplot(data=bioassay.fac,mapping = aes(y = uterus,x = ZM,color=lab))+
  geom_boxplot()+theme_bw()+facet_wrap(~ protocol)+
  geom_text(data=bioassay.fac[outliers,],
            aes(label=outliers,color=lab))
#+theme(legend.position="bottom",
#       legend.title=element_blank())
##caculate the mean for different group 
#bioassay.fac %>% group_by(ZM) %>% summarize(mean=mean(uterus,na.rm=T))

##4var:EE
ggplot(data=bioassay.fac,mapping = aes(y = uterus,x = EE,color=lab))+
  geom_boxplot()+theme_bw()+facet_wrap(~ protocol)+
  geom_text(data=bioassay.fac[outliers,],
            aes(label=outliers,color=lab))
#+scale_colour_discrete(guide = FALSE)
##caculate the mean for different group.
#bioassay.fac %>% group_by(EE) %>% summarize(mean=mean(uterus,na.rm=T))

##weights
ggplot(data=bioassay.fac,mapping = aes(y = uterus,x = weight))+
  geom_point()+geom_smooth(method = "lm")+theme_bw()+facet_wrap(~ protocol,scales = "free")+
  geom_text(data=bioassay.fac[outliers,],
            aes(label=outliers,color=lab))

```

####Model and Results

```{r lm.full.fac, message=FALSE, warning=FALSE, paged.print=FALSE}
lm.full.fac=lm(data = bioassay.fac[-c(1586,926),],formula = uterus~EE+ZM+lab+protocol+weight+EE:protocol+ZM:protocol+EE:lab+ZM:lab) 

#plot(lm.full.fac) ##use the plot to check model assumption. (detect outliers, normality, influential points.)

#bioassay.fac %>% select(EE,ZM) %>% table() -- there is imbalanced distribution 

#summary(lm.full.fac)
#Adjusted R-squared:  0.9538 

##if consider EE,ZM as numeric
#lm.full.q=lm(data = bioassay,formula = #uterus~poly(EE,2)+poly(ZM,2)+lab+protocol+weight+EE:protocol+ZM:protocol+EE:lab+ZM:lab)
#anova(lm.full.q)
#summary(lm.full.q) #0.8286 #p=69 
```

```{r functions,  message=FALSE, warning=FALSE, paged.print=FALSE}
eff.tbl=function(lm.obj){
  if (is.matrix(lm.obj)){
    ind.mat=matrix(0,nrow=ncol(lm.obj),ncol=7)
    colnames(ind.mat)=c("EE","ZM","lab","protocol","EEdose","ZMdose","interaction")
    ind.mat=cbind(coef=lm.obj%>%colnames(.),ind.mat)
  }else{
    ind.mat=matrix(0,nrow=nrow(summary(lm.obj)$coefficients),ncol=7)
    colnames(ind.mat)=c("EE","ZM","lab","protocol","EEdose","ZMdose","interaction")
    ind.mat=cbind(coef=summary(lm.obj)$coefficients%>%rownames(.),ind.mat)
  }
  
  ind.mat[str_detect(ind.mat[,1],"EE"),"EE"]=1
  ind.mat[str_detect(ind.mat[,1],"ZM"),"ZM"]=1
  ind.mat[str_detect(ind.mat[,1],"EE.*protocol"),"interaction"]=1
  ind.mat[str_detect(ind.mat[,1],"ZM.*protocol"),"interaction"]=1
  ind.mat[str_detect(ind.mat[,1],"EE.*lab"),"interaction"]=1
  ind.mat[str_detect(ind.mat[,1],"ZM.*lab"),"interaction"]=1
  for (dose in c(bioassay.fac$EE %>% levels())){
     ind.mat[str_detect(ind.mat[,1],paste0("EE",dose)),"EEdose"]=dose
  }
  for (dose in c(bioassay.fac$ZM %>% levels())){
     ind.mat[str_detect(ind.mat[,1],paste0("ZM",dose)),"ZMdose"]=dose
  }
  for (lab in c(bioassay.fac$lab %>% levels())){
     ind.mat[str_detect(ind.mat[,1],paste0("lab",lab)),"lab"]=lab
  }     
  for (protocol in c(bioassay.fac$protocol %>% levels())){
     ind.mat[str_detect(ind.mat[,1],paste0("protocol",protocol)),"protocol"]=protocol
  }  
  ind.tbl=ind.mat%>% as.tibble()
  return(ind.tbl)
}

t.test=function(lm.obj,str.ee,str.lab,str.ori){
ind.tbl=eff.tbl(lm.obj)
cov.coef=vcov(lm.obj)
p=nrow(ind.tbl)
i.levels=bioassay.fac %>% pull(str.ori) %>% levels() #original colnames in bioassay.fac
i.n=i.levels %>% length(.)
lambda=matrix(nrow=i.n,ncol=nrow(ind.tbl))
lab.ee=t.value=p.value=denominator=nominator=numeric(i.n)

for (i in 1:i.n){
  lambda[i,]=((ind.tbl[str.lab]==i.levels[i])&(ind.tbl[str.ee]=="1"))|((ind.tbl[str.ee]=="1")&(ind.tbl["interaction"]=="0"))
  lab.ee[i]=summary(lm.obj)$coefficients[lambda[i,],"Estimate"] %>% sum()
  denominator[i]=(cov.coef[lambda[i,],lambda[i,]]) %>% sum() %>% sqrt() 
  nominator[i]=lab.ee[i] %>% abs()
  t.value[i]=(nominator[i])/(denominator[i])
  p.value[i]=pt(q = t.value[i],df = summary(lm.obj)$df[2],lower.tail = FALSE)
}

res=list(t.test=tibble(i.levels,p.value,estimator=lab.ee),value=tibble(i.levels,variance=denominator,estimator=nominator))
return(res)
}
```

a.1

uterotrophic bioassay successful overal at identifying effects of EE and ZM. F-test for EE,ZM are significant. For the significant coefficients, all EE are positive, ZM are negative. 

```{r part1.result, warning=FALSE, paged.print=FALSE}
#0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


anova(lm.full.fac)

coefs=rownames(summary(lm.full.fac)$coefficients)

res=summary(lm.full.fac)$coefficients %>%
  cbind(coef=coefs,.) %>% 
  as.tibble() #get the coefficients matrix

colnames(res)=c("coef","estimate","std_error","t_value","p_value")

res %>% filter(as.numeric(p_value)<0.05) %>% slice(1:10)
```

a.2 do some labs fail to detect such effects

There are some labs fail to detect such effects, as follows:"Huntingd""Bayer""ChungKor""TNO""Zeneca". Or just pick out the labs with significant p value at "EE:lab_i" but opposite t value. ("Huntingd""Bayer""Zeneca") 

```{r}
a.2.ee=t.test(lm.full.fac,"EE","lab","lab")$t.test
a.2.ee
a.2.ee %>% filter(((p.value<0.05)&(estimator<0))|(p.value>0.05))# %>% pull(i.levels)

a.2.zm=t.test(lm.full.fac,"ZM","lab","lab")$t.test
a.2.zm
a.2.zm %>% filter(((p.value<0.05)&(estimator>0))|(p.value>0.05))#%>% pull(i.levels)

res %>% filter(str_detect(res$coef,"EE.*lab")) %>%
   filter(p_value<0.05,t_value<0)
res %>% filter(str_detect(res$coef,"ZM.*lab")) %>%
   filter(p_value<0.05,t_value<0)
```

a.3 the change dose for EE? vary across labs?

From the output of summary(See the end of part I). The change dose for EE is EE3. Dose larger than this is significant, less than this is not significant. The value varies across labs. Because for different labs, the dose changing points is different. For example, SUmitomo. EE0.3 may be the changing dose point. For Huntingd, EE0.1 may be the changing dose point.

b. does the dose reponse vary across labs? are there certain labs stands out as being different?
From the output of summary. There exist several significant interaction cofficients, meaning dose reponse vary across labs. The labs Berlin and Sumitomo stands out as being different.(with pvalue<0.001 for EE:labs). The labs Bayer,Poulenc,Zeneca stands out as being different.(with pvalue<0.005 for ZM:labs)

```{r}
res %>% filter(str_detect(res$coef,"EE.*lab")) %>%
  filter(p_value<0.001)

res %>% filter(str_detect(res$coef,"ZM.*lab")) %>%
  filter(p_value<0.005)
```


c.Do the protocols differ in sensitivity to detect? Which one recommend?

From the result from anova. The protocols differ. And the variance of protocol C,D is super large. Protocol A and B would be recommended.

```{r}
anova(lm.full.fac)["EE:protocol", ]
anova(lm.full.fac)["ZM:protocol", ]

res %>% filter(str_detect(res$coef,"^protocol"))

res %>% filter(str_detect(res$coef,"EE.*protocol")) 

res %>% filter(str_detect(res$coef,"ZM.*protocol"))

```


### Part II

With the same model, using Bayesian Average Model to estimate the parameter with hyper-g-n prior(mixture prior). To answer the questions, I mainly concentrate on inclusion probability, posterior model probability and the shape of posterior distribution for $\beta_i$ (or confidence interval). 

```{r bays.fac.1.gprior,echo=FALSE,eval=FALSE}
#EE+ZM+lab+protocol+weight+EE:protocol+ZM:protocol+EE:lab+ZM:lab
n=nrow(bioassay.fac)
X.fac.1=model.matrix(data=bioassay.fac,object =~ EE+ZM+lab+protocol+weight+EE:protocol+ZM:protocol+EE:lab+ZM:lab)
p=ncol(X.fac.1)-1
bas.fac.1=bas.lm(formula =uterus~EE+ZM+lab+protocol+weight+EE:protocol+ZM:protocol+EE:lab+ZM:lab,
                 data=bioassay.fac,
                 prior="g-prior",
                 alpha=n,
                 #n.models=20000,
                 method = "MCMC",
                 thin=10,
                 #initprobs = "eplogp",
                 MCMC.iterations = 500000)
bas.fac.1
image(bas.fac.1)
plot(bas.fac.1)
#summary(bas.fac.1)
coef(bas.fac.1) %>% plot(.,ask=F)
##diagonose
diagnostics(bas.fac.1,"pip")
#cv.summary.bas()
```

```{r bays.fac.1.hypergn}
n=nrow(bioassay.fac)

bas.fac.2=bas.lm(formula =uterus~EE+ZM+lab+protocol+weight+EE:protocol+ZM:protocol+EE:lab+ZM:lab,
                 data=bioassay.fac,
                 prior="hyper-g-n",
                 alpha=n,
                 #n.models=20000,
                 method = "MCMC",
                 thin=10,
                 #initprobs = "eplogp",
                 MCMC.iterations = 500000)

##diagonose
diagnostics(bas.fac.2,"pip")
##More iteration would be better
```

a.1 Similar to Part I, we want to test whether the coefficients before `EE` all equal to 0. Here I use sum posterior model probabiliters over all models that include `EE`, is 0.99982. Similar for ZM,is 0.99982. For the coefficients `EE` with high inclusion probability, all of them are larger than 0 with high probability. Simlar for `ZM `(negative). So the method successful overall at identifying effects.

```{r part2.a.1}

a_1=function(str_ee){
  which.mat=list2matrix.which(bas.fac.2,)
  ind.tbl.bas=eff.tbl(X.fac) #part II model assumption is the same to part I
  head(ind.tbl.bas)
  ind.var=((ind.tbl.bas[str_ee]=="1")&(ind.tbl.bas$interaction=="0"))
  n.ind=sum(ind.var)
  poll.in=(which.mat[,ind.var] %*% rep(1,n.ind))>0
  res=list(prob=sum(poll.in*bas.fac.2$postprobs),ind=ind.var)
  return(res)
}



a_1("EE")$prob
a_1("ZM")$prob

#image(bas.fac.2)--to much predictor, cannot visualization
#plot(bas.fac.2)

par(mfrow=c(2,2))
ind.ee=which(a_1("EE")$ind)
coef(bas.fac.2) %>% plot(.,ask=F,subset=ind.ee)
ind.zm=which(a_1("ZM")$ind)
coef(bas.fac.2) %>% plot(.,ask=F,subset=ind.zm)

```

a.2 Concerntrate on `EE:lab_i`, `ZM:lab_i`. Pick out the labs with high inclusive probability but opposite location compared to others. ("Huntingd""Zeneca""TNO""KoreaPar""ChungKor""Poulenc""EnvTox") Simply, the rule is for   `EE`, if `EE:lab_i` is at the left side of the verticle black line and the verticle black line is short, we may consider the lab fail to detect. Similar for `ZM`.

```{r,eval=FALSE,echo=FALSE}
coef(bas.fac.2) %>% plot(.,ask=F)

#bas.a_2=function(lm.obj,int.tbl,str.ee,str.lab,str.ori){
#p=nrow(ind.tbl)
#i.levels=bioassay.fac %>% pull(str.ori) %>% levels() #original colnames in bioassay.fac
#i.n=i.levels %>% length(.)
#lambda=matrix(nrow=i.n,ncol=nrow(ind.tbl))
#lab.ee=prob=numeric(i.n)
#for (i in 1:i.n){
#  lambda[i,]=((ind.tbl[str.lab]==i.levels[i])&(ind.tbl[str.ee]=="1"))|((ind.tbl[str.ee]=="1")&(ind.tbl["int#eraction"]=="0"))
#  n.ind=sum(lambda[i,])
#  poll.in=(which.mat[,lambda[i,]] %*% rep(1,n.ind))>0
#  prob[i]=sum(poll.in*lm.obj$postprobs)
#  }
#res=list(prob.res=tibble(i.levels,probability=prob),ind=lambda)
#return(res)
#}
#ind.tbl.bas=eff.tbl(X.fac)
#a_21=bas.a_2(bas.fac.2,ind.tbl.bas,"EE","lab","lab")
#a_21$prob.res
#a_22=bas.a_2(bas.fac.2,ind.tbl.bas,"ZM","lab","lab")
#a_22$prob.res
#
#ind.ee=which(a_21$ind[2,])
#coef(bas.fac.2) %>% plot(.,ask=F,subset=ind.ee)
#ind.zm=which(a_22$ind)
#coef(bas.fac.2) %>% plot(.,ask=F,subset=ind.zm)


```

a.3 Concerntrate on `EE`,`ZM`, see which dose level the inclusive probability significantly change. EE1. And concerntrate on  `EE:lab_i`,`ZM:lab_i` to see which dose level the inclusive probability significantly change. They vary.

b. The dose response vary across labs, because there exist `EE:lab_i`,`ZM:lab_i` with high inclusive probability. There are certain labs ("Huntingd""Zeneca""TNO""KoreaPar""ChungKor""Poulenc""EnvTox") stand out as being different.

c.Protocols differ in the sensitivity to detect effects. Protocol B would be recommended because the length of CI for `protocolB:EE` and `protocolB:ZM` are small compared to others.

```{r}

coefs=rownames(confint(coef(bas.fac.2)))
ci.length=apply(confint(coef(bas.fac.2)),1,function(x) as.numeric(x[2])-as.numeric(x[1]))
  
bas.coef=confint(coef(bas.fac.2)) %>%
  cbind(coef=coefs,.) %>% 
  as.tibble() %>% #get the coefficients matrix
  mutate(ci.length=ci.length)

bas.coef %>% filter(str_detect(coef,"EE.*protocol")) %>% arrange(sort(ci.length)) %>% slice(1:10)

bas.coef %>% filter(str_detect(coef,"ZM.*protocol")) %>% arrange(sort(ci.length)) %>% slice(1:10)

```



###Part III


Because I set iteration=30000, and include many predictors. So the jags would be slow. So I load the data I got. An improvement for this is to adjust the distribution for $\sigma_L^2/\lambda_l$ behave like double exponential distribution. The hyperparameter a here is important for adjusting whether we want our model more robust. I chose a=2 for I want to let my model get less sensitive to labs "outliers". I use credible interval to answer these questions.

Prepare the data

```{r message=FALSE, warning=FALSE, paged.print=FALSE}

# Create a data list with inputs for JAGS

X.fac=model.matrix(data=bioassay,object =~EE+ZM+lab+protocol+weight+EE:protocol+ZM:protocol+EE:lab+ZM:lab)[,-1]
n=nrow(bioassay)
## scale X such that X^TX has ones on the diagonal;
## scale divides by the standard deviation so we need
## to divide by the sqrt(n-1)
scaled.X = scale(X.fac)/sqrt(n-1)
# are diagonal elements 1?
# check
#t(scaled.X) %*% scaled.X
data = list(Y = bioassay$uterus, 
            X=scaled.X, 
            p=ncol(scaled.X),
            n = n)

#extract the scales from the scaled object and fix--add to attr
data$scales = attr(scaled.X, "scaled:scale")*sqrt(n-1) # fix scale
data$Xbar = attr(scaled.X, "scaled:center")

```

Jags code

```{r jags, eval=FALSE}
##For jags: need to use <-; use precision instead of sigma_sq
rr.model = function() {
  a <- 2
  shape<-a/2

  for (i in 1:n) {
    mu[i] <- alpha0 + inprod(X[i,], alpha)
    prec[i] <- phi
    Y[i] ~ dnorm(mu[i], prec[i])
  }
  phi ~ dgamma(1.0E-6, 1.0E-6)  ##jags do not allow improper prior
  alpha0 ~ dnorm(0, 1.0E-6) 

  for (j in 1:p) {
    phi.l[j] <- pow(i.phi.l[j], -2)    
    prec.beta[j] <- lambda.l[j]*phi*phi.l[j]
    alpha[j] ~ dnorm(0, prec.beta[j])
    # transform back to original coefficients
    beta[j] <- alpha[j]/scales[j]
    lambda.l[j] ~ dgamma(shape, shape)
    i.phi.l[j] ~ dt(0,1,1)%_%T(0,)

  }

  # transform intercept to usual parameterization 
  beta0 <- alpha0 - inprod(beta[1:p], Xbar)

  sigma <- pow(phi, -.5)
}

# parameters to monitor
parameters = c("beta0", "beta", "sigma","lambda.l", "phi.l")

# run jags from R  (see Resources to install)
stack.sim.hfac = jags(data, 
                 inits=NULL, 
                 par=parameters,
                 model=rr.model, 
                 n.iter=30000)
saveRDS(stack.sim.hfac, "stack.sim.rds")
stack.sim=readRDS("stack.sim.rds")
```

Load the data I stored.

```{r load.data}
stack.sim=readRDS("stack.sim.rds")
```

Analysis on simulation result.


```{r message=FALSE, warning=FALSE, paged.print=FALSE}
# create an MCMC object with the results for the MCMC draws
stack.mcmc = as.mcmc(stack.sim$BUGSoutput$sims.matrix)  #get the simulation points

quan=function(x){
  qu=quantile(x,c(.025, .975))
  avg=mean(x)
  res=c(qu,avg=avg)
  return(res)}
ci.all=apply(stack.mcmc,2,quan) %>% t(.)
mcmc.df=stack.mcmc %>% as.tibble()
```


a.1 The method is successful overall at identifying effects because the credible interval for `EE` is above 0, the credible interval for `ZM` is below 0.

```{r}
##code from https://stackoverflow.com/questions/21310609/ggplot2-box-whisker-plot-show-95-confidence-intervals-remove-outliers 

X.fac.jags=model.matrix(data=bioassay,object =~EE+ZM+lab+protocol+weight+EE:protocol+ZM:protocol+EE:lab+ZM:lab)[,-1]

quantiles_95 <- function(x) {
  r <- quantile(x, probs=c(0.05, 0.25, 0.5, 0.75, 0.95))
  names(r) <- c("ymin", "lower", "middle", "upper", "ymax")
  r
}

mcmc.df.beta=mcmc.df %>% select(`beta[1]`:`beta[2]`) 
names(mcmc.df.beta)=c("EE","ZM")
mcmc.df.beta = mcmc.df.beta %>% gather(.)
ggplot(data = mcmc.df.beta,mapping = aes(x = key,y = value,fill=as.factor(key)))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+ guides(fill=FALSE)+stat_summary(fun.data = quantiles_95, geom="boxplot")

```

a.2 There are labs Poulenc,ChungKor,EnvTox,Zeneca,KoreaPar,Hungtingd fail to detect such effects.(below the 0)

```{r echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
realname=X.fac.jags %>% colnames()
jagsname=mcmc.df %>% names()

temp.ee.lab=jagsname[str_detect(realname,"EE.*lab")] 
real.tag=realname[str_detect(realname,"EE.*lab")]
mcmc.df.beta=mcmc.df %>% select(temp.ee.lab[1:18]) 
colnames(mcmc.df.beta)=real.tag
mcmc.df.beta = mcmc.df.beta %>% gather(.)
ggplot(data = mcmc.df.beta,mapping = aes(x = key,y = value,fill=as.factor(key)))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+ guides(fill=FALSE)+stat_summary(fun.data = quantiles_95, geom="boxplot")+geom_hline(yintercept = 0)

temp.zm.lab=jagsname[str_detect(realname,"ZM.*lab")] 
real.tag=realname[str_detect(realname,"ZM.*lab")]
mcmc.df.beta=mcmc.df %>% select(temp.zm.lab[1:18]) 
colnames(mcmc.df.beta)=real.tag
mcmc.df.beta = mcmc.df.beta %>% gather(.)
ggplot(data = mcmc.df.beta,mapping = aes(x = key,y = value,fill=as.factor(key)))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+ guides(fill=FALSE)+stat_summary(fun.data = quantiles_95, geom="boxplot")+geom_hline(yintercept = 0)


```

a.3 what the change point for the dose for `EE`. Under the model that `EE` and `ZM` are continuous, based on the linear regression assumption, we may think 1 is the change point. However, it is not rigorous. This changing point may vary across labs but it is hard to get the conclusion directly.

```{r message=FALSE, warning=FALSE, paged.print=FALSE}
mcmc.df.beta=mcmc.df %>% pull(`beta[1]`) 
a=0.01*mcmc.df.beta
b=0.03*mcmc.df.beta
c=mcmc.df.beta
d=3*mcmc.df.beta
e=10*mcmc.df.beta
mcmc.df.beta=cbind(y=c(a,b,c,d,e),x=rep(c("0.01","0.03","1","3","10"),each=nrow(mcmc.df))) %>% as.tibble() %>%
  mutate(y=as.numeric(y))

ggplot(data = mcmc.df.beta,mapping = aes(x = as.factor(x),y=y,fill=factor(x)))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+ guides(fill=FALSE)+geom_boxplot()+
  scale_x_discrete(limits=c("0.01","0.03","1","3","10"))


```

b.The dose response vary across labs. See from the credible interval "boxplot" for a.2. The position and length(with color-- 95% credible interval) for each lab is different. Lab Poulenc,Huntingd stands out as being different. However, there are still some overlap between the "outliers" and other labs. So we may say they are not too different from others.

c.The protocol differ in the sensitivity to detecting the effects especially for `EE`. Protocol B is recommended for its lower variance compared to others. 

```{r message=FALSE, warning=FALSE, paged.print=FALSE}
#consider sigma as measuring error

temp.ee.lab=jagsname[str_detect(realname,"^protocol")] 
real.tag=realname[str_detect(realname,"^protocol")]
mcmc.df.beta=mcmc.df %>% select(temp.ee.lab[1:3],sigma) 
colnames(mcmc.df.beta)=c(real.tag,"sigma")
mcmc.df.beta = mcmc.df.beta %>% gather(.)
ggplot(data = mcmc.df.beta,mapping = aes(x = key,y = value,fill=as.factor(key)))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+ guides(fill=FALSE)+stat_summary(fun.data = quantiles_95, geom="boxplot")+geom_hline(yintercept = 0)

temp.ee.lab=jagsname[str_detect(realname,"EE.*protocol")] 
real.tag=realname[str_detect(realname,"EE.*protocol")]
mcmc.df.beta=mcmc.df %>% select(temp.ee.lab[1:3],sigma) 
colnames(mcmc.df.beta)=c(real.tag,"sigma")
mcmc.df.beta = mcmc.df.beta %>% gather(.)
ggplot(data = mcmc.df.beta,mapping = aes(x = key,y = value,fill=as.factor(key)))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+ guides(fill=FALSE)+stat_summary(fun.data = quantiles_95, geom="boxplot")+geom_hline(yintercept = 0)

temp.zm.lab=jagsname[str_detect(realname,"ZM.*protocol")] 
real.tag=realname[str_detect(realname,"ZM.*protocol")]
mcmc.df.beta=mcmc.df %>% select(temp.zm.lab[1:3],sigma) 
colnames(mcmc.df.beta)=c(real.tag,"sigma")
mcmc.df.beta = mcmc.df.beta %>% gather(.)
ggplot(data = mcmc.df.beta,mapping = aes(x = key,y = value,fill=as.factor(key)))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+ guides(fill=FALSE)+stat_summary(fun.data = quantiles_95, geom="boxplot")+geom_hline(yintercept = 0)

mcmc.df.lambda=mcmc.df %>% select(`lambda.l[1]`:`lambda.l[66]`) %>% gather(.)
mcmc.df.phi.l=mcmc.df %>% select(`phi.l[1]`:`phi.l[66]`) %>% gather(.)
beta.levels=paste0("beta[",1:66,"]","beta0")
lambda.levels=paste0("lambda.l[",1:66,"]")
phi.l.levels=paste0("phi.l[",1:66,"]")

```

### Table for the whole model

```{r}
kable(summary(lm.full.fac)$coefficients, format = "markdown")
```


```{r}
bas.coef.need=bas.coef[,-5]
kable((bas.coef.need), format = "markdown")
```

```{r}
kable((ci.all), format = "markdown")
```
